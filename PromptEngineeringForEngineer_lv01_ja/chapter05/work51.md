---
seq: 57
title: 練習問題
slug: chapter05/work51
description: 曖昧な実装計画を具体的で実行可能な計画に改善するメタ認知テクニックを学ぶ
type: exercise
relation: chapter05/work2
difficulty: 3
displayLanguage: ja
duration: 20
---
# 品質の改善（メタ認知）- AIに計画を具体化させる

## 練習問題

:::exercise
**【シチュエーション】**
2ページ目のAIとの対話を経て、高橋さんは「Eager Loadingの実装」が、1ヶ月という短納期で顧客の信頼を勝ち取るための最善策であると確信しました。次のステップとして、彼はAIに具体的な実装計画の骨子を作成させました。

**▼ AIが最初に作成した実装計画の骨子**
> 1.  対象のクエリを特定する。
> 2.  特定した箇所にEager Loadingを適用する。
> 3.  パフォーマンステストを行い、改善を確認する。

この計画を見た高橋さんは、頭を抱えました。「これでは計画とは言えない。あまりに漠然としていて、これを見た若手エンジニアは『で、具体的にどうすれば？』と必ず聞きに来るだろう。もっと作業手順が目に浮かぶような、実践的なアクションプランに深化させなければ…。」

**【課題】**
AIが生成したこの**抽象的な計画**を、**具体的で実践的なタスクリスト**に深化させるためのメタ認知プロンプトを作成してみましょう。

:::

:::Hint
AIが生成したリストや計画が具体的でない場合、その**「曖昧さ」**をAI自身に指摘させ、より解像度の高い情報を引き出すメタ認知プロンプトが有効です。

* **ヒント①：AIに「レビュー担当者」の役割を与える**
    * 「あなた自身が、この計画の**レビューを担当するシニアエンジニア**だとしたら？」と問いかけてみましょう。AIは自らの回答を客観視し、足りない点を探し始めます。

* **ヒント②：「曖昧な点」を質問させる**
    * ただレビューさせるだけでなく、「この計画の**どの部分に『具体的にどうやるの？』と質問したくなりますか？**」と、AIに具体的な質問を言語化させることが重要です。これにより、AIは「何を具体的にすべきか」を自己認識できます。

* **ヒント③：質問に答えさせ、計画を再構築させる**
    * 最後に、AIが自ら挙げた質問に答えさせる形で、計画を書き換えさせましょう。「その質問に答える形で、元の計画を**より具体的で実践的なものに書き換えてください**」と指示するのが効果的です。
:::

<details>
<summary>練習問題プロンプト例</summary>
```
この実装計画の骨子を作成していただき、ありがとうございます。
しかし、これではまだ計画として不十分で、チームメンバーが具体的な作業に移れません。

そこで、あなた自身がこの計画をレビューするシニアエンジニアの立場だと想像してください。
この計画の曖昧な点について、思わず「具体的にどうやるの？」と確認したくなる質問を3つ挙げてください。

そして、その質問に自ら答える形で、元の計画を誰でも実行可能な、具体的で実践的なタスクリストに書き換えてください。
```
### AIの出力例
```
承知いたしました。シニアエンジニアの視点で、提示された計画をレビューし、より実践的なタスクリストに具体化します。

レビューで確認したい3つの質問
質問1: 「対象のクエリを特定する」とありますが、具体的にどのツールを使い、何を基準に「ここが原因だ」と特定するのですか？

質問2: 「Eager Loadingを適用する」際のコードレビューでは、特にどんな点に注意すべきですか？将来、再びパフォーマンス問題を起こさないためのチェック観点はありますか？

質問3: 「改善を確認する」テストは、どのような環境で、何を基準に「改善した」と判断するのですか？また、万が一、本番環境で問題が発生した場合の切り戻し手順はありますか？

具体的なタスクリストへの書き換え
以上の質問に答える形で、以下のようにタスクリストを具体化します。

【N+1クエリ問題 改善アクションプラン】

フェーズ1：調査・特定 (期間：3日間)

[ボトルネックの特定]: New RelicやDatadog等のAPMツールを使用し、APIエンドポイントごとの平均レスポンスタイムを計測。最も遅延の大きいエンドポイントを特定する。

[該当クエリの特定]: 特定したエンドポイントのログを詳細に調査し、実際に発行されているSQLクエリを確認。ループ内で繰り返し実行されているN+1クエリの箇所をコードレベルで特定する。

[現状の数値計測]: 開発環境で、特定した処理の実行時間を10回計測し、平均値を記録する。（例：平均2,500ms）

フェーズ2：実装・レビュー (期間：5日間)
4.  [開発ブランチの作成]: feature/fix-n1-query のような専用ブランチを作成する。
5.  [Eager Loadingの実装]: 特定した箇所に、使用しているORMの作法（例: includes, JOIN FETCH）に従い、Eager Loadingを適用する。
6.  [コードレビューの実施]: プルリクエストを作成し、チームメンバーからレビューを受ける。
* レビュー観点:
* N+1問題が解消されているか。
* 過剰にデータを取得していないか（Select句で必要なカラムを明示するなど）。
* コードの可読性が下がっていないか。

フェーズ3：テスト・リリース (期間：2日間)
7.  [改善効果の測定]: 開発環境で、修正後の処理の実行時間を再度10回計測し、平均値が目標値（例：500ms以下）を達成しているか確認する。
8.  [ステージング環境での検証]: ステージング環境にデプロイし、関連機能に意図しない副作用（デグレ）が発生していないか、QAチームと連携して確認する。
9.  [本番リリース]: メンテナンス時間を設け、本番環境へリリースする。リリース後、30分間はAPMツールでパフォーマンスを監視する。
10. [切り戻し手順の確認]: 万が一、リリース後に重大な問題が発覚した場合は、事前に用意した手順に従い、即座に一つ前のバージョンにロールバックする。
```

</details>
:::memo
お疲れ様でした。
次のワークでは、AIが自ら改善した戦略案を基に、最終的な提案書を作成し、その論理的な正しさをAI自身に検証させる方法について学んでいきましょう。
:::


