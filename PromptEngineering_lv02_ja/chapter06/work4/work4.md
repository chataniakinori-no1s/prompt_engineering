#### ワーク4: 条件分岐による対話制御とコスト最適化

Work3で作成したチャットボットは、登録された文書（ナレッジベース）の中からその質問に最も関連性の高い部分を検索して、回答生成することが可能になりました。
しかし、塚本さんが実際に運用してみると、新たな課題として「コスト」の側面が見えてきました。

> **【新たな依頼：管理部 塚本さん】**
> 「FAQボットが対応してくれて助かります！ただ分析してみると、社員が単に『ありがとう』とお礼を言っただけの時も、AIが一生懸命に社内文書全体を検索しているようなんです。これは無駄なコスト（トークン）がかかっていますよね？
> 雑談や挨拶の時はナレッジ検索をせず、本当に情報が必要な時だけ検索するように賢く制御して、コストを最適化できませんか？」

この課題を解決するために、**ユーザーの意図に応じて処理の流れを分岐させる「条件分岐」**の技術を学びます。これにより、AIの挙動をより精密に制御し、不要な処理をなくしてコスト効率の高いアプリケーションを構築します。

---

### 実践：コスト効率と対話性能を両立したFAQボットへの改良

作成するアプリケーションの全体像は以下のようになります。
1.  ユーザーの質問が「雑談・挨拶」なのか「知識を必要とする質問」なのかをAIが分類する。
2.  「知識を必要とする質問」の場合のみ、ナレッジを検索し、その結果を基に回答を生成する。
3.  「雑談・挨拶」の場合は、ナレッジ検索を行わず、シンプルな応答を返すことでコストを最小限に抑える。

それでは、Work3で作成したチャットボットをベースに、この新しい機能を追加していきましょう。

#### Step 1: ユーザーの意図を分類する (質問分類器の追加)

まず、ユーザーの入力がナレッジ検索を必要とするか否かを判断する「門番」を設置します。これにより、不要なナレッジ検索を実行しないように制御し、コストを削減します。

1.  Difyで新しいチャットフローを作成し、「条件分岐チャットボット」などの名前をつけます。
2.  `開始` ノードの `+` ボタンを押し、`[質問分類器]` ノードを追加します。
3.  **質問分類器ノードの設定**:
    * `入力変数` に `sys.query` が設定されていることを確認します。
    * `クラス` の設定で、以下の2つの分類を作成します。
        * `クラス1`: `社内規定に関する質問`
        * `クラス2`: `その他`
    * `高度な設定` を開き、`メモリ` のトグルをONにします。（Work2で学んだ通り、分類時にも過去の会話を考慮させるためです）

4.  **【プロンプト応用】分類精度を高めるための指示**
    `指示` の入力欄に、Few-Shot（少数例示）を応用したプロンプトを記述し、分類精度を高めます。
    ```
    ユーザーの質問を以下のクラスに分類してください。会話の文脈も考慮して、最も適切なクラスを一つだけ選択してください。

    # クラス定義と判断例
    ## 社内規定に関する質問
    ユーザーが会社のルール、マニュアル、手続きについて質問している場合に選択します。
    例:
    - 「経費精算の方法を教えて」
    - 「リモートワークのルールは？」
    - 「それの申請手続きは？」

    ## その他
    上記に当てはまらない、挨拶、雑談、感謝などの一般的な会話の場合に選択します。
    例:
    - 「こんにちは」
    - 「ありがとう！」
    - 「今日の天気は？」
    ```

#### Step 2: ナレッジを検索し、回答を生成するルートの作成

次に、分類器が「社内規定に関する質問」と判断した場合のルートを作成します。このルートはWork3で作成したRAGの仕組みとほぼ同じです。

1.  `質問分類器` ノードの `社内規定に関する質問` の分岐から `+` ボタンを押し、`[知識取得]` ノードを追加します。
2.  **知識取得ノードの設定**:
    * `クエリ変数` に、ユーザーの元の質問である `sys.query` を設定します。
    * `ナレッジ` に、Work3で作成した社内文書のナレッジを選択します。
3.  `知識取得` ノードの次に `LLM` ノード（`RAG回答LLM`）を追加します。
4.  **RAG回答LLMノードの設定**:
    * `コンテキスト` に `知識取得` ノードの `result` を設定します。
    * `ユーザー入力` に `sys.query` を設定します。
    * `メモリ` 機能をONにします。
    * Work3と同様の「制約条件」を持つシステムプロンプトを設定します。

#### Step 3: 出力の集約と安定化（変数集約器）

最後に、2つの異なるルート（RAG回答ルートと挨拶ルート）の結果を、安定して`回答`ノードに渡すための処理を追加します。

1.  **挨拶への応答**: `質問分類器` の `その他` の分岐から、別の `LLM` ノード（`挨拶LLM`）を追加し、「フレンドリーに挨拶を返してください」といったプロンプトとメモリ設定を行います。
2.  **`変数集約器`ノードの追加と設定**:
    * Step2の`RAG回答LLM`と、このステップの`挨拶LLM`の次に、`[変数集約器]`ノードを配置します。
    * ノードの設定を開き、`ソース変数`を2つ定義します。（例: `rag_output` と `greeting_output`）
    * `RAG回答LLM`の出力を`rag_output`に、`挨拶LLM`の出力を`greeting_output`に接続します。
    * **`グループ化メソッド`を`結合`に設定します。** これにより、どちらか一方のルートから渡された有効な変数（空でない方）を、後続のノードに渡すことができます。
3.  **`回答`ノードへの接続**: `変数集約器`の出力（`result`）を、最後の`回答`ノードに接続します。

> **【解説】なぜ`変数集約器`が必要なのか？**
> `回答`ノードは、チャットの応答を逐次表示（ストリーミング）する機能を持っています。しかし、複数のLLMから直接接続すると、どの接続を優先してストリーミングすべきか混乱し、意図しないルートの出力が表示されたり、何も表示されなかったりする場合があります。
> `変数集約器`を間に挟むことで、**複数のルートからの出力を、単一の安定した変数（データストリーム）に統合**できます。これにより、`回答`ノードは常に一つの入力元だけを見ればよくなり、どちらのルートが実行されても、その結果を確実かつ安定してユーザーに表示できるようになります。これは、複雑な分岐を持つアプリケーションを堅牢にするための重要なテクニックです。

#### Step 4: 動作確認

すべての設定が完了したら、プレビュー画面で動作を確認しましょう。

* **挨拶**: `「ありがとう」`と入力 → 挨拶LLMだけが動き、ナレッジ検索が実行されない（コストが削減されている）ことを確認。
* **RAG**: `「育児休業について教えて」` → `「男性も取得できますか？」`と連続入力 → RAGルートが正しく動き、文脈を理解した回答が返ってくることを確認。

お疲れ様でした！ これで、コスト効率と対話性能を両立した、より実践的なAIチャットボットが完成しました。