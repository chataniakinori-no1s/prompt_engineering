---
seq: 12
title: ツールの連携による自動化の拡張
slug: chapter02/work10
description: Difyのツール連携機能を活用し、要件定義書を元にした調査と設計書作成の自動化パイプラインを構築する
type: work
difficulty: 3
displayLanguage: ja
duration: 30
relation: chapter02/index,chapter02/work09
---

# ツールの連携による自動化の拡張

先ほどのワークでは、ワークフローの基本構造を学びました。しかし、実際の業務自動化では、単にAIに文章を生成させるだけでなく、外部の情報（ファイルやWebサイト）を参照したり、他のツールと連携させたりする場面が頻繁にあります。

ここでは、Difyの自動化能力をさらに引き出す「**ツール連携**」に焦点を当てます。高橋さんの課題解決に向け、ユーザーがアップロードした「要件定義書」をAIが読み解き、それを基に**Tavily Searchで質の高い技術調査を行い、次のWork3で設計書を作成できる形に検索結果を整える**という、より実践的な自動化パイプラインの構築に挑戦します。


## Difyのツール連携を理解しよう

Difyの自動化（チャットフローとワークフロー）の真価は、LLMだけでなく、様々な「ツール」をパイプラインに組み込める点にあります。

### ツールとは？

Difyにおける「ツール」とは、LLM以外の特定の機能を持つノードです。これらをマーケットプレイスから追加しパイプラインに組み込むことで、あなたの自動化アプリケーションは単なる文章生成器から、多機能な業務システムへと進化します。

マーケットプレイスには、以下のような様々なカテゴリーのツールがあります。

* **Web情報収集ツール**: **Tavily Search**など。言語モデルでの利用に最適化された検索結果や、Webページの内容を取得します。
* **生産性向上ツール連携**: **Slack**, **Notion**, **Google Workspace**など。日々の業務で使うツールに通知を送ったり、会議の議事録を自動で書き込んだりします。
* **マルチモーダルAIツール**: **Stable Diffusion** (画像生成) や **ElevenLabs** (音声合成) など。テキストだけでなく、画像や音声も扱えるようになります。
* **カスタムAPIツール**: **外部API呼び出し**ツールなど。社内システムや外部の様々なサービス（例：天気予報API、株価API）と連携し、自動化の可能性を無限に広げます。

これらのツールをLLMと組み合わせることで、「**Webで技術情報を収集し → LLMに分析・要約させ → 結果を設計書としてまとめる**」といった、人間の知的労働を模倣した複雑な自動化が実現可能になるのです。

## 実践：要件から技術調査を行い結果を整形するワークフローを作成する

### ✅ 実践の前に：Tavily Searchツールの準備をしよう 🔧

このワークでは **Tavily Search** を使用します。これは外部のサービスと連携するため、APIキーの設定が必要です。

**Tavily Search APIキーの取得方法:**

1.  [Tavily公式サイト](https://tavily.com)にアクセスし、アカウントを作成します。
2.  ログイン後、ダッシュボードでAPIキーを発行し、安全な場所にコピーしておきます。
3.  執筆時点では、月1000回までのAPIコールは**無料**で利用できます。

**Difyへのツール追加:**

1.  Dify画面上部のメニューから `ツール` を選択します。
2.  `マーケットプレイス` で `Tavily Search & Extract` を検索し、`インストール` をクリックします。
3.  `ツール` タブに戻り、`Tavily Search` の `認証を設定` をクリックします。
4.  先ほど取得した **APIキー** を入力して保存します。

これで、ワークフローでTavily Searchが使えるようになりました。

### Step 1: ワークフローの準備と開始ノードの設定

まず、ユーザーが要件定義書をアップロードするための入り口（トリガー）を作ります。

1.  ワークフローを新規に作成します。
2.  `開始` ノードをクリックし、ファイルアップロード用の変数を1つ作成します。
    * **フィールドタイプ**: `単一ファイル`, **変数名**: `requirements_doc`, **ラベル名**: `要件定義書`, **サポートされたファイルタイプ**: `ドキュメント`に✅, **必須**: ON

### Step 2: ドキュメントからテキストを抽出する（ドキュメントを抽出ノード）

**【解説】**
LLMノードに直接ファイル変数を渡すと、Difyの内部的なファイル処理が原因で予期せぬエラーが発生することがあります。この問題を回避するため、Difyに**デフォルトで搭載されている「ドキュメントを抽出」ノード**を使い、アップロードされたファイルから安全にテキスト情報だけを抜き出します。

1.  `開始` ノードの次に、`ツール`カテゴリの中にある `ドキュメントを抽出` ノードを追加します。
2.  `ファイル` の入力欄に、開始ノードのファイル変数 `{{#start.requirements_doc#}}` を設定します。
3.  このノードは、PDFやDOCX、TXTなど様々な形式のファイルからテキストを抽出し、文字列として出力します。


### Step 3: ステップバック思考でリサーチクエリ配列を生成する（リサーチ戦略LLM）

要件定義書から直接検索するのではなく、AIに「**調査すべき核心的な問い**」を考えさせ、後のイテレーション処理で使えるように**JSON配列形式**で出力させます。

1.  `開始` ノードの次に `LLM` ノードを追加します。
2.  `システムプロンプト` に、JSON配列形式でクエリを出力するよう指示を貼り付けます。

```markdown

# 役割
あなたは、大規模Webサービスの開発経験が豊富な、世界トップクラスのシステムアーキテクトです。同時に、技術的な課題を解決するために、最も効果的な検索クエリを組み立てることに長けた熟練のリサーチャーでもあります。

# 背景
渡された要件定義書は、これから開発する新機能の概要です。あなたのタスクは、ステップバック思考を用いて、技術設計の成功に不可欠な「調査すべき核心的なテーマ」を特定し、それに基づいた最適な検索クエリを生成することです。

# 指示
以下の要件定義書の内容を深く分析し、この機能の技術設計を行う上で調査・検証すべき最も重要なテーマを5つ特定してください。次に、各テーマについて、検索エンジンで最も関連性の高い情報を引き出すための**キーワードを組み合わせた検索クエリ**を生成してください。

# 制約条件
- 各クエリは、具体的な技術選定、アーキテクチャパターン、セキュリティリスク、スケーラビリティに関する内容を含むこと。
- **完全な自然言語の文章ではなく、検索エンジンに最適化された3〜5個程度の重要なキーワードの組み合わせを生成してください。**
- **出力は検索クエリの文字列を要素とするJSON配列のみ**とし、マークダウンや説明文など余計な情報は絶対に含めないでください。

# 少数例示 (Few-Shot Example)
## 入力となる要件定義書の例:
 「ユーザー同士がリアルタイムでテキストメッセージを送り合えるチャット機能を追加する。オンラインステータスの表示も必要。」
```

## 期待する出力形式例 (JSON):
```json
[
"real-time chat WebSocket SSE scalability comparison",
"WebSocket security best practices hijacking injection",
"chat user presence online status scalable architecture",
"chat message broker AWS SQS RabbitMQ comparison",
"chat message history database performance millions"
]
```

3.  `ユーザー入力` に `{{#start.requirements_doc#}}` を設定します。

### Step 4: クエリ文字列を配列型に変換する (コード)

**【解説】**
LLMノードが出力したのは、あくまでJSON形式の「**文字列**」です。一方、次のイテレーションノードが処理できるのは、Difyのネイティブな「**配列(Array)型**」のデータのみです。このため、間にコードノードを挟んで、文字列から配列型へとデータ形式を変換してあげる必要があります。

1.  `LLM` ノードの次に `コード` ノードを追加します。
2.  入力変数 `llm_output_string` に `{{#llm_1.text#}}` を設定します。
3.  以下のPythonコードを貼り付けて、JSON文字列をPythonのリスト（Difyの配列型に対応）に変換します。

```python
import json

def main(llm_output_string: str) -> dict:
    """
    LLMが出力したJSON文字列をパースし、
    文字列のリスト、またはオブジェクトのリストのどちらにも対応して、
    最終的に文字列のリストを返す。
    """
    try:
        data = json.loads(llm_output_string)
        
        # データがリスト形式でなければ、空のリストを返す
        if not isinstance(data, list):
            return {"queries_array": []}
            
        queries_list = []
        for item in data:
            # ケース1: リストの要素が辞書の場合（例: {"query": "..."}）
            if isinstance(item, dict):
                # "query" キーの値を取得。存在しない場合は空文字
                query_text = item.get("query", "")
                if query_text: # 空文字でなければ追加
                    queries_list.append(query_text)
            # ケース2: リストの要素が既に文字列の場合
            elif isinstance(item, str):
                queries_list.append(item)
                
        return {"queries_array": queries_list}

    except (json.JSONDecodeError, TypeError):
        # 変換に失敗した場合は空のリストを返す
        return {"queries_array": []}

```

4.  出力変数 `queries_array` を `Array(String)` 型として設定します。

### Step 5: 複数の検索クエリを並列実行する (イテレーション & Tavily Search)

配列型に変換された複数の検索クエリを一つずつ、かつ高速に実行するため、イテレーションノードの**パラレルモード**を活用します。

1.  `コード` ノードの次に `イテレーション` ノードを追加します。
2.  イテレーションノードの設定で、`入力` に **Step 3のコードノードが出力した配列** `{{#コード実行（配列変換）.queries_array#}}` を指定し、`パラレルモード` を **ON** にします。
3.  イテレーションノード内の `+ブロックを追加` をクリックし、`ツール` タブから `Tavily Search` ノードを配置します。
4.  `Tavily Search` の入力変数 `Query` に `{{#イテレーション.item#}}` を設定します。

## パラレルモードの利点と注意点

### 利点
パラレルモードをONにすると、複数の検索（APIコール）が同時に実行されます。例えば5つの検索クエリがあり、1回の検索に3秒かかるとします。通常（逐次実行）では 3秒 × 5回 = 15秒 かかりますが、パラレルモードでは理論上は約3秒で完了します。このように、API連携など待ち時間が発生する処理を複数回行う場合に、ワークフロー全体の実行時間を大幅に短縮できるのが最大のメリットです。

### 課題
非常に便利な機能ですが、Difyのバージョンや実行環境によっては、同時に完了した各処理の結果を正しく一つに集約できない場合があります。その結果、「最後のキーワードの検索結果しか次のノードに渡されない」といったデータ欠損の問題が発生することがあります。

### 回避策
もし後続のステップでデータが不足しているなどの問題が発生した場合は、まずパラレルモードをOFFにして、逐次実行（一つずつ順番に実行）で試すのが最も確実な解決策です。 逐次実行は時間はかかりますが、各ステップの結果を確実につなぐことができます。


### Step 6: 検索結果をスコアでフィルタリングする (コード @イテレーション内部)

Tavily Searchの検索結果には関連性スコアが含まれています。スコアが低い結果を除外し、情報の精度を高めます。この処理はループの内部で行います。

1.  イテレーションノード内の `Tavily Search` ノードの次に `コード` ノードを追加します。
2.  コードノードの入力変数 `arg1` に `{{#Tavily Search.json#}}` を設定します。
3.  以下のPythonコードを貼り付け、関連スコアが `0.5` 以上の結果のみを抽出します。

```python
def main(arg1: list[dict]) -> dict:
    threshold = 0.5 # 関連性のスコアの閾値
    filtered_results = []
    for result in arg1[0].get("results", []):
        if result.get("score", 0) >= threshold:
            filtered_results.append({
                "title": result.get("title"),
                "url": result.get("url"),
                "content": result.get("content"),
                "score": result.get("score"),
            })
    return {
        "filtered_results_per_query": filtered_results,
    }
```
4.  コードノードの出力変数 `filtered_results_per_query` を `Array(Object)` 型として設定します。
5.  イテレーションノードの `出力` に、このコードノードの出力 `{{#コード実行（スコアでフィルタリング）.filtered_results_per_query#}}` を設定します。


### Step 7: ネストした配列をフラットに整形し、各検索結果を文字列に変換 (コード)

**【解説】**
パラレル実行されたイテレーションノードの出力は、各ループの結果をまとめた「**配列の配列**」（例: `[[検索1の結果], [検索2の結果], ...]`) というネストした構造になります。
このままでは後続のLLMが扱いにくいため、オブジェクトの配列をLLMが読みやすい単一の文字列に変換するようにします。

1.  `イテレーション` ノードの次に、新しい `コード` ノードを追加します。
2.  入力変数 `nested_array` に、イテレーションノード全体の出力 `{{#イテレーション.output#}}` を設定します。
3.  以下のPythonコードを貼り付け、配列の配列を一つの配列にまとめます。

```python
import json

def main(nested_array: list) -> dict:
    """
    入力された配列（ネストされている場合もフラットな場合も対応）を
    単一のフラットなリストに整形し、その後、LLMが読みやすい
    マークダウン形式の単一の文字列に変換して出力する。
    """
    final_flat_list = []
    
    # --- STEP 1: 配列をフラットにする ---
    if nested_array and isinstance(nested_array[0], list):
        # 入力が「配列の配列」の場合
        for sublist in nested_array:
            for item in sublist:
                if isinstance(item, dict):
                    final_flat_list.append(item)
    else:
        # 入力がすでに「フラットな配列」の場合
        for item in nested_array:
            if isinstance(item, dict):
                final_flat_list.append(item)

    # --- STEP 2: フラットなリストを単一の文字列に変換する ---
    if not final_flat_list:
        return {"final_search_results": "関連する検索結果は見つかりませんでした。"}

    formatted_string_chunks = []
    for i, result in enumerate(final_flat_list):
        # .get()を使い、キーが存在しない場合でもエラーを防ぐ
        title = result.get('title', 'タイトルなし')
        url = result.get('url', 'URLなし')
        content = result.get('content', '内容なし')
        score = result.get('score', 0)

        # 各検索結果をマークダウン形式のテキストブロックに整形
        chunk = (
            f"## 検索結果 {i+1}\n\n"
            f"### タイトル: {title}\n"
            f"**URL:** {url}\n"
            f"**関連スコア:** {score:.4f}\n\n"
            f"**内容:**\n{content}\n"
        )
        formatted_string_chunks.append(chunk)

    # 全てのテキストブロックを区切り線で結合して、最終的な単一の文字列を作成
    final_string = "\n---\n\n".join(formatted_string_chunks)
    
    return {"final_search_results": final_string}
```

4.  出力変数 `final_search_results` を `String` 型として設定します。

### Step 8: 終了ノードで最終結果を確認する

整形された最終的な検索結果をワークフローの出力として設定します。

1.  **Step 7のコードノード**の出力を `終了` ノードに接続します。
2.  `終了` ノードでコードノードの出力 `{{#コード実行（配列の整形）.final_search_results#}}` を選択します。

### Step 9: テストと実行

実行画面で、パイプラインが正しく動作するか確認しましょう。

1.  画面右上の `実行` をクリックします。
2.  `要件定義書` のフォームにテキストファイルをアップロードし、`実行` します。
3.  最終的な出力として、AIが生成した**3つの問い**に基づき、Tavilyで並列検索・フィルタリングされ、**フラットな単一の配列に整形された質の高い情報**のリストがJSON形式で表示されれば成功です。

お疲れ様でした！ これで、外部ファイルから情報を読み込み、**ステップバック思考**で自律的に質の高いWeb調査を行い、**その結果を次の分析フェーズで利用しやすい形に整形する**、高度な自動化パイプラインが完成しました。

次のWork3では、この整形された調査結果をさらに別のLLMに分析・要約させ、最終成果物である設計書を生成します。


