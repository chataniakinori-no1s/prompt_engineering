---
seq: 25
title: 練習問題 リスク分析
slug: chapter03/work13
description: ペルソナを活用して、プロジェクトの潜在的なリスクを分析する
type: exercise
relation: chapter03/work11
difficulty: 3
displayLanguage: ja
duration: 15
---

# ペルソナ実践（リスク分析）

:::exercise
## 練習問題

**【シチュエーション】**
田中さんは、セールストークも準備でき、いよいよ企画会議が間近に迫ってきました。しかし、彼はふと「この企画、良いことばかりじゃないよな…」と不安になります。会議で厳しい役員から想定外のリスクを指摘され、立ち往生する事態だけは避けたいと考えています。

彼が開発しようとしている「AIアシスタント」は、**ユーザーからの自然言語での質問に答えて操作方法を案内したり、レポート作成を自動化したりする機能**です。

さあ、実際にChatGPTやGeminiなどの対話AIを使って、この企画の「リスク」を網羅的に洗い出させるプロンプトを作成してみましょう。
:::

:::Hint
物事をポジティブな側面から見るペルソナもいれば、その逆も可能です。AIに、あえて「悲観的」で「批判的」なペルソナを与えることで、自分では気づきにくい潜在的なリスクや、計画の甘さを浮き彫りにすることができます。ここでも、シチュエーション説明にある機能概要をプロンプトに含めることが重要です。
:::

<details>
<summary>練習問題プロンプト例</summary>
```
あなたは、常に最悪の事態を想定する、非常に優秀で悲観的なリスク管理の専門家です。
現在、我々が企画している新機能「AIアシスタント」について、考えられるビジネス上のリスクを、厳しい視点から3つ指摘してください。

# 新機能「AIアシスタント」の概要
- ユーザーが自然言語で質問すると、アプリケーションの操作方法や最適な機能などを対話形式で教えてくれる。
- 複雑なレポート作成なども、AIに指示するだけで自動で実行してくれる。
```

### AI回答出力例
（AIによる回答のイメージ）
```
リスク管理の観点から、この「AIアシスタント」企画に潜む重大なリスクを3点指摘します。楽観的な見通しは今すぐ捨ててください。

1.  **【誤情報による信用の失墜リスク】**: AIアシスタントが誤った操作方法を教えたり、間違ったデータでレポートを作成したりした場合、顧客の業務に深刻な損害を与える可能性があります。たった一度のミスが、我々が長年かけて築き上げてきた製品への信頼を根底から覆すことになるでしょう。

2.  **【コスト増大による収益圧迫リスク】**: AIの運用には、高価なAPI利用料や高性能なサーバー維持費が継続的に発生します。もし有料プランへの移行が想定通りに進まなかった場合、この機能は収益を生まない「金食い虫」となり、会社全体の利益を圧迫するだけの存在になりかねません。

3.  **【顧客サポートの崩壊リスク】**: 「AIが何でも答えてくれる」と顧客が過度に期待した場合、AIが解決できない複雑な問題が、これまで以上にサポート窓口に殺到する可能性があります。結果として、サポート部門は疲弊し、本当に重要な顧客への対応が遅れ、顧客満足度が逆に低下するという最悪の事態も想定すべきです。
```
</details>

