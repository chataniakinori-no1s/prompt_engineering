# ワーク1-2: なぜ「質問力」が重要なのか？ - AIの得意・不得意とハルシネーション

## サンプル課題

あなたが利用しているAIチャットに、以下の質問を投げかけてみましょう。
```
2025年に日本で公開されたSF大作映画『ギャラクシー・プロンプト』のあらすじと、世間の評価を教えてください。
```

AIはどのような回答を生成したでしょうか？もっともらしいあらすじや、俳優名、肯定的なレビューなどを生成したかもしれません。

しかし、この映画『ギャラクシー・プロンプト』は**実際には存在しません。**

## Point
AIは事実でない情報を、さも事実であるかのように生成することがあります。これを**ハルシネーション（幻覚）**と呼びます。AIの回答を鵜呑みにせず、常に「これは本当か？」と疑う視点を持ち、最終的な事実確認（ファクトチェック）は人間が行うことが極めて重要です。

## 解説

### 解説1: AIは「嘘」をつく？ - ハルシネーションの正体

サンプル課題で体験したように、AIは存在しない映画のあらすじを創作しました。これがハルシネーションです。

これは、AIが「嘘をつこう」と悪意を持っているわけではありません。その理由は、AIの頭脳である**大規模言語モデル（LLM）**が持つ仕組みにあります。

#### Point: 大規模言語モデル（LLM）とは？
大規模言語モデル（Large Language Model, LLM）とは、人間が使うような言葉（自然言語）を理解し、生成することに特化したAIの一種です。

- **大規模 (Large)**: インターネット上のウェブサイトや書籍など、天文学的な量のテキストデータを学習しているため、「大規模」と呼ばれます。
- **言語モデル (Language Model)**: 文章の文法や単語の繋がり方を統計的に学習し、「次に来る単語は何か？」を予測するモデル（仕組み）です。

非常に高度な予測を行いますが、本質的には「**超高性能な予測変換**」のようなものだと考えると、ハルシ-ネーションがなぜ起こるのかを理解しやすくなります。

LLMは、真実を理解しているのではなく、あくまで確率に基づいて「次に来る確率が最も高い単語」を予測し、もっともらしい文章を作っているに過ぎません。そのため、学習データにない情報や、曖昧な質問をされると、学習したパターンを組み合わせて「それらしい嘘」を生成してしまうのです。

### 解説2: 「AIの面接官」になるために - 得意・不得意を理解する

AIの能力を最大限に引き出すには、その得意・不得意を理解することが不可欠です。AIを「万能の神」ではなく、特定のスキルセットを持つ「候補者」と捉え、その能力を見極める「面接官」のような視点を持ちましょう。

**AIの得意なこと（採用したいスキル）**
- **文章の生成・要約・翻訳**: ブログ記事の作成、長文レポートの要約、多言語への翻訳など、テキスト処理全般。
- **アイデア出し（ブレインストーミング）**: 新規事業のアイデア、キャッチコピーの提案など、発想を広げる壁打ち相手。
- **構造化されたテキストの作成**: プログラミングコード、HTML、JSON、表形式のデータなど、決まった形式での出力。
- **文章の分類・感情分析**: 文章がポジティブかネガティブかの判定や、問い合わせ内容のカテゴリ分け。

**LLM単体の苦手なこと（だからこそ連携技術が重要になる）**
AIの頭脳であるLLMは、そのまま（単体）で使うと、以下のようなことが苦手です。この弱点を理解することが、後の章で学ぶ「外部連携」などの応用技術の重要性を理解する鍵となります。

- **事実確認（ファクトチェック）**: ハルシネーションが示す通り、情報の正確性は保証されません。**最終的な事実確認は必ず人間が行う必要があります。**
- **最新・リアルタイムな情報**: LLM単体では、学習データが特定の時点までのため、「今日のニュース」や「現在の株価」などには対応できません。**（※この弱点は、後の章で学ぶWeb検索などの「外部連携」で克服できます）**
- **複雑な計算・厳密な論理推論**: 簡単な計算はできますが、高度な数学の問題や厳密な論理展開は苦手な場合があります。**（※この弱点も、計算ツールなどと「外部連携」することで克服可能です）**

#### Warning
AIに個人情報や企業の機密情報を入力してはいけません。入力したデータが、AIモデルの学習に利用される可能性があります。サービスを利用する際は、必ず利用規約やプライバシーポリシーを確認しましょう。

### サンプル課題の「答え」と正しい向き合い方

この課題の本当の「答え」は、『その映画は存在しない』という事実に気づくことです。では、どうすればそれに気づけたのでしょうか？AIを鵜呑みにせず、以下のような「検証の質問」をすることが有効です。

1.  **情報源を尋ねる**:
    AIがもっともらしい回答をしてきたら、その情報の出所を尋ねます。ハルシネーションの場合、AIはURLを提示できないか、偽のURLを生成します。
    ```
    その情報はどこで確認できますか？参考にした映画情報サイトやレビューサイトのURLを教えてください。
    ```

2.  **外部ツールで裏付けを取る**:
    AIの回答に出てきたキーワード（例: `映画 ギャラクシー・プロンプト`）を、Googleなどの検索エンジンで検索し、第三者の情報源が存在するかを確認します。

3.  **AIの知識範囲を尋ねる**:
    AI自身の能力について質問し、回答の信頼性を探ります。
    ```
    あなたの知識はいつまでの情報に基づいていますか？
    ```

このように、AIを疑い、対話を通じて検証する姿勢こそが、AIを使いこなす上で重要な「質問力」の一部です。

---

## 練習問題

AIの「苦手なこと」を理解した上で、以下の3つのプロンプトを見てみましょう。それぞれ、なぜ「LLM単体で実行するには不適切な質問」と言えるのか、その理由をAIの苦手なことから選んで説明してください。

1.  `今日の渋谷駅周辺の天気と、おすすめの傘を教えて。`
2.  `当社の来期の経営戦略を、競合A社の動向も踏まえて立案してください。`
3.  `絶対に成功する新商品のアイデアを1つだけ教えて。`

### Hint
それぞれの質問が、LLM単体のどの「苦手なこと」に抵触しているかを考えてみましょう。「最新情報」「機密情報」「事実の保証」などがキーワードです。

### 練習問題解説

これらのプロンプトは、AIがその能力を発揮できない、不得意な領域で指示を出してしまっているため、「不適切な質問」と言えます。

1.  **今日の天気**: LLM単体では**リアルタイムな情報**にアクセスできません。過去の天気のパターンから「晴れでしょう」と予測するかもしれませんが、それは天気予報ではありません。
2.  **来期の経営戦略**: LLM単体では、企業の内部情報（財務状況、人材、企業文化など）や、競合A社の**機密情報**を知りません。そのため、具体的で実行可能な戦略は立案できず、一般的な経営論しか返せません。
3.  **絶対に成功するアイデア**: LLM単体では未来を予測できません。「成功する」という**事実を保証することは不可能**です。アイデアのブレインストーミングは得意ですが、その成功を約束することはできません。

### 練習問題解答
1.  **理由**: LLM単体では**最新・リアルタイムな情報**を持っていないため。
2.  **理由**: LLM単体では企業の**機密情報**を知らないため。
3.  **理由**: LLM単体では**事実を保証したり、未来を予測したりする**ことができないため。

---

お疲れ様でした。
このワークでは、AIを疑うことの重要性と、LLM単体の限界を学びました。次のワークでは、AIがなぜ賢いのか、その仕組みの基本に触れていきます。