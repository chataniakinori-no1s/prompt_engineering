### 【実践課題】: 新たなクレームに高度なプロンプト戦略で挑む

お疲れ様でした。いよいよこの章の総仕上げです。
高橋さんが実装したパフォーマンス改善は成功しましたが、新たな、より複雑な問題が浮上しました。この新しい課題に対し、これまで学んだ3つの高度なスキル（ステップバック、メタ認知、自己検証）を一つずつ活用して、解決に導くプロンプトを作成してみましょう。

---
**【シチュエーション】**

パフォーマンス改善プロジェクトは大成功。翻訳APIは高速化され、顧客からのクレームも激減しました。しかし数週間後、プロダクトマネージャーの田中さんが、新たな相談を高橋さんの元へ持ってきました。

> **田中さん:**
> 「高橋さん、APIは速くなって本当に助かっているんだ。ただ、今度は別のお客様から、『翻訳の品質』に関する新しいクレームが来ていてね。『専門用語や、うちの会社独自の固有名詞の翻訳が、意味不明な言葉になってしまう。これでは海外の支社と正確なコミュニケーションが取れず、かえって業務に支障が出ている』とのことなんだ。何か良い手はないだろうか？」

> **高橋さんの思考:**
> 「なるほど、速度の次は『品質』ですか…。確かに、汎用的な翻訳APIだと、専門用語の翻訳精度には限界がありますね。単純なバグ修正とは違う、もっと根本的な機能追加が必要そうだ。どうアプローチすればいいだろう…。」

---

### 課題1: 問題の本質を探る (ステップバックの応用)

**【あなたのタスク】**
田中さんからの「専門用語の翻訳品質を上げてほしい」という要望に対し、すぐに「ユーザー辞書機能を作ろう」と解決策に飛びつくのは危険です。まずは一歩引いて、この問題の技術的な本質と、考えられるアプローチの全体像を把握する必要があります。

**【Hint】**
ワーク1で学んだ**「ステップバック」**の考え方を応用します。AIに、いきなり解決策を求めずに、まずは**「そもそも、この問題を技術的に解決するには、どのようなアプローチが考えられるか？」**という、より上位の問いを投げかけてみましょう。AIに**「機械翻訳システムを専門とするリサーチエンジニア」**の役割を与え、「専門用語の翻訳精度を向上させるための技術的アプローチを、複数の異なる観点から網羅的に洗い出してください」と依頼することで、あなたが思いもよらなかった解決策の選択肢を得られ、技術選定の視野を広げることができます。

---

### 課題2: 解決策の品質を高める (メタ認知の応用)

**【あなたのタスク】**
ステップバックによる分析の結果、複数の技術的アプローチが考えられることが分かりました。高橋さんは、その中でも最も現実的な「ユーザー辞書機能」を実装する方針を固め、その基本的なデータベース設計をAIに依頼しました。

**▼ AIが提案したDBスキーマ（初稿）**
```sql
CREATE TABLE user_dictionaries (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    source_term VARCHAR(255) NOT NULL,
    target_term VARCHAR(255) NOT NULL
);
```
このスキーマはシンプルですが、高橋さんは「大量の辞書データが登録された時のパフォーマンスは？」「単語だけでなく、複数の単語からなるフレーズには対応できるのか？」といった、エンジニアならではの懸念を抱きました。

**【Hint】**
ワーク2で学んだ**「メタ認知」**を使い、AIに自らの提案をレビューさせましょう。AIが作ったシンプルな設計案は、時として非機能要件（パフォーマンス、拡張性など）の考慮が浅いことがあります。そこでAIに**「大規模サービスの運用経験が豊富な、データベース管理者（DBA）」**という役割を与えます。「このDBスキーマ設計について、パフォーマンスと拡張性の観点から、考えられる問題点を3つ指摘してください」と問いかけることで、AIは自ら考慮漏れを発見し、より堅牢な設計を考えるきっかけを与えてくれます。

---

### 課題3: 提案の信頼性を固める (自己検証の応用)

**【あなたのタスク】**
AIとの対話を通じて、カスタム辞書機能のDB設計はより洗練されたものになりました。高橋さんは、この設計をチームに共有するための簡単な技術説明ドキュメントをAIに作成させました。

**▼ AIが作成した技術説明（初稿）**
> **カスタム辞書機能のDB設計について**
> 今回の機能では、ユーザー辞書を格納するため、`user_dictionaries`テーブルを新設します。このテーブルは、`source_term`（原文）と`target_term`（訳文）のカラムを持ち、B-treeインデックスを`source_term`に付与することで、高速な検索を実現します。

この説明は簡潔ですが、なぜこの設計が最適なのか、他の選択肢はなかったのか、という点については触れられていません。

**【Hint】**
ワーク3で学んだ**「自己検証」**を使い、AIに文章の論理的な正当性を自己評価させましょう。今回は**「提案された技術に対して、常にあえて代替案を考える、批判的な視点を持つアーキテクト」**というペルソナを与え、その視点から文章をレビューさせます。「このDB設計の説明を読んで、あなたが『なぜその技術選択なのですか？他の方法も考えられますよね？』と反論したくなるであろう点を指摘してください。その上で、その反論に備える形で、なぜこの設計が合理的であるかを補強する説明を追記してください」と指示することで、技術選定の理由が明確になり、チームの合意形成を円滑にするドキュメントを完成させることができます。

---
### 【実践課題】プロンプト例とAI回答出力例

**▼ 課題1プロンプト例**
```
# 役割
あなたは、自然言語処理と機械翻訳システムを専門とするリサーチエンジニアです。

# 背景
当社のサービスが利用している汎用的な翻訳APIで、「専門用語や固有名詞の翻訳精度が低い」という問題が起きています。

# 指示
この問題を解決するために、技術的に考えられるアプローチを、できるだけ網羅的に挙げてください。
それぞれの方法について、どのような技術で、どのようなメリット・デメリットがあるのかを簡潔に説明してください。
```

**▼ 課題1 AI回答出力例**
```
承知いたしました。リサーチエンジニアとして、専門用語の翻訳精度を向上させるための技術的アプローチを網羅的に解説します。

### 専門用語翻訳の精度向上アプローチ

**1. 用語集（Glossary）機能の実装**
- **技術概要**: ユーザーが「原文」と「訳文」のペアを辞書として登録し、翻訳時にその辞書をAPIに渡すことで、指定した単語を強制的に置換する機能。多くの翻訳APIでサポートされています。
- **メリット**: 実装が比較的容易。ユーザー自身で辞書をメンテナンスできる。
- **デメリット**: 文脈を無視して置換するため、不自然な翻訳になることがある。単語単位でしか機能しない場合が多い。

**2. 翻訳モデルのファインチューニング（Fine-tuning）**
- **技術概要**: 汎用的な翻訳モデルに対し、特定のドメイン（業界など）の大量の対訳データを追加で学習させることで、そのドメインに特化した翻訳モデルを作成する技術。
- **メリット**: 文脈を考慮した、非常に自然で高精度な専門用語の翻訳が期待できる。
- **デメリット**: 大量の高品質な対訳データが必要。モデルの学習と運用に高いコストと専門知識が必要。

**3. RAG（Retrieval-Augmented Generation）の活用**
- **技術概要**: 翻訳したい文章に関連する専門用語の対訳例を、ベクトルデータベースなどから高速に検索（Retrieval）し、その情報をプロンプトに含めてLLMに翻訳させる（Generation）技術。
- **メリット**: ファインチューニングほどの大量データは不要で、リアルタイムに知識を追加・更新できる。
- **デメリット**: プロンプトエンジニアリングの工夫が必要。検索の精度が、最終的な翻訳品質に大きく影響する。
```

**▼ 課題2プロンプト例**
```
このDBスキーマ設計案をありがとうございます。
```sql
CREATE TABLE user_dictionaries (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    source_term VARCHAR(255) NOT NULL,
    target_term VARCHAR(255) NOT NULL
);
```
では次に、あなた自身がこのDBスキーマをレビューする、大規模サービスの運用経験が豊富なデータベース管理者（DBA）の立場で、この設計を評価してください。

パフォーマンスと拡張性の観点から、このシンプルな設計が将来的に引き起こす可能性のある問題点を3つ指摘してください。
```

**▼ 課題2 AI回答出力例**
```
承知いたしました。DBAとして、このスキーマ設計の潜在的な問題点を指摘します。

**1. 複合インデックスの欠如によるパフォーマンス劣化**
- **問題点**: 現在の設計では、`user_id`と`source_term`で検索するクエリが多発すると予想されますが、`id`にしか主キーインデックスがありません。`source_term`だけで検索するケースは少なく、多くは「特定のユーザーの、特定の単語」を探すはずです。このままでは、`user_id`で絞り込んだ後、`source_term`でテーブルをフルスキャンする非効率なクエリが実行される可能性があります。
- **推奨**: `(user_id, source_term)`の複合インデックスを追加すべきです。

**2. `VARCHAR(255)`の非効率性**
- **問題点**: `source_term`は単語だけでなく、複数の単語からなるフレーズ（例：「人工知能学会」）が登録される可能性があります。`VARCHAR(255)`では長さが足りなくなるケースが考えられます。逆に、ほとんどが短い単語である場合、この固定長の定義はディスクスペースの無駄遣いになる可能性もあります。
- **推奨**: `TEXT`型への変更を検討するか、あるいは`source_term`の最大長を要件として明確に定義すべきです。

**3. テナント（企業）単位でのデータ管理の考慮漏れ**
- **問題点**: この設計はユーザー個人に辞書が紐付いていますが、B2Bサービスでは「企業単位」で辞書を共有したいという要求が必ず出てきます。現状のままでは、企業内の全ユーザーが同じ単語をそれぞれ登録する必要があり、非効率かつ管理が煩雑になります。
- **推奨**: `user_id`だけでなく`tenant_id`（企業ID）もカラムに追加し、辞書を企業単位で管理できるような拡張性を考慮した設計にすべきです。
```

**▼ 課題3プロンプト例**
```
この技術説明をありがとうございます。
```
> **カスタム辞書機能のDB設計について**
> 今回の機能では、ユーザー辞書を格納するため、`user_dictionaries`テーブルを新設します。このテーブルは、`source_term`（原文）と`target_term`（訳文）のカラムを持ち、B-treeインデックスを`source_term`に付与することで、高速な検索を実現します。
```
では最後に、この説明をレビューしてください。
あなたは、提案された技術に対して、常にあえて代替案を考える、批判的な視点を持つアーキテクトです。
この説明を読んで、「なぜその技術選択なのですか？他の方法も考えられますよね？」と反論したくなるであろう点を指摘してください。
その上で、その反論に備える形で、なぜこの設計が合理的であるかを補強する説明を追記してください。
```

**▼ 課題3 AI回答出力例**
```
承知いたしました。アーキテクトとして、この技術説明の弱点を指摘し、補強します。

### 弱点の指摘
この説明では、「なぜ辞書データをRDB（リレーショナルデータベース）に格納するのか」という、最も根本的な設計判断の理由が述べられていません。
私ならこう反論します。「辞書のような単純なKey-Valueストアなら、RDBよりもRedisやDynamoDBのようなNoSQLデータベースの方が、読み取り性能も高く、スケーラビリティにも優れているのではありませんか？」

### 説明の補強案
この反論に備え、以下のように説明を補強することを提案します。

---
**【改善後】カスタム辞書機能のDB設計について**

今回の機能では、ユーザー辞書を格納するため、**既存のMySQL（RDB）内に**`user_dictionaries`テーブルを新設します。

**【技術選定の理由】**
辞書データのようなKey-Value形式のデータストアには、RedisのようなNoSQLデータベースも選択肢として考えられます。しかし、今回は以下の理由から、既存のRDBを利用することが最も合理的であると判断しました。

1.  **開発スピードの優先**: 新たなミドルウェア（Redis等）を導入する場合、環境構築、運用監視、学習コストが発生します。今回は、まず顧客価値を迅速に提供することを最優先とし、使い慣れたRDBを選択します。
2.  **データの一貫性と管理の容易さ**: ユーザー情報など、他のデータと一貫性を保ったバックアップや管理が可能です。
3.  **将来的な拡張性**: 将来的には、企業単位での共有機能や、単語の承認ワークフローといった複雑な機能追加が予想されます。こうしたリレーショナルな要件には、RDBの方が柔軟に対応できます。

テーブルには、`source_term`（原文）と`target_term`（訳文）のカラムを持ち、B-treeインデックスを`source_term`に付与することで、RDBでも十分に高速な検索を実現します。
---
